{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Example _de novo_ GBS analysis using _pyRAD_"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "----------  \n",
      "\n",
      "Please direct questions about _pyRAD_ usage to the google group thread ([link](https://groups.google.com/forum/#!forum/pyrad-users))  \n",
      "\n",
      "--------------  \n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This tutorial focuses on the analysis of single-end GBS reads and also methods for salvaging short fragments containing adapter sequence that can result from poor size selection in a number of library preparation methods.  \n",
      "\n",
      "If you have not yet read the [full tutorial](http://nbviewer.ipython.org/gist/dereneaton/ba1e04f0a757ee9f859d), you should start there for a broader description of how _pyRAD_ works.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This tutorial is written as an IPython notebook. Each cell beginning with the header (%%bash) or with (!) should be executed in a command line shell, for example by copying and pasting the text (but excluding the line %%bash or !). If you have IPython installed on your machine you can download this notebook and edit/execute the cells yourself.  \n",
      "\n",
      "-------------  \n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###A short description of the genotyping-by-sequencing (GBS) library preparation.  \n",
      "\n",
      "Genomic DNAs are digested with a single restriction enzyme such that fragments have the same cutsite overhang on both ends.  Barcodes and adapters are ligated to these fragments, they are amplified using PCR, and fragments within a certain size window are selected for sequencing.  \n",
      "\n",
      "GBS, like ddRAD, are cheaper to produce than RAD, and easier to prepare in your own lab. The size selection step is often the most difficult to reproduce, and is an important step to perform correctly because short fragment DNA are particularly troublesome for GBS analyses since fragments can be sequenced from either end (The barcode+Illumina adapter can ligate to either end). If for example your library contains many fragments that are less than 200 bp, and you sequence 100 bp reads, the reads from either end of duplicate fragments will overlap to produce duplicates of the same region.  \n",
      "\n",
      "In this tutorial I show how to test whether overlap occurs in your GBS data, and how to setup the params file to perform reverse complement clustering in the case that it does occur; or to not perform this type of clustering if your data do not overlap (reverse complement clustering is much slower.)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "--------------  \n",
      "\n",
      "The bash script in the cell below can be used to download an example GBS data set and unarchive it into your current directory. This data set was simulated with the following parameters\n",
      "\n",
      "+ 12 taxa, 1 sampled individual per taxon  \n",
      "+ 1000 GBS loci (500 DNA fragments sequenced from each end as first reads)  \n",
      "+ 20X sequencing depth\n",
      "+ theta = 0.014  \n",
      "+ sequencing error rate = 0.005  \n",
      "+ no mutations to restriction sites\n",
      "+ no indels   \n",
      "+ fragment size window (150-350)    \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "## paste the commands below into your terminal\n",
      "wget http://goo.gl/oFCvzG 2&> /dev/null\n",
      "unzip oFCvzG\n",
      "rm oFCvzG"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Archive:  oFCvzG\n",
        "  inflating: simGBS.barcodes         \n",
        "  inflating: simGBS_R1_001.fastq.gz  \n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "The two necessary files below should now be located in your current directory/"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "+ simGBS_R1_001.fastq.gz : Illumina fastQ formatted reads (gzip compressed)\n",
      "+ simGBS.barcodes : barcode map file"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "We begin by creating the params.txt file, which sets all of the parameters for the pyrad analysis."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! ~/pyrad_v.1.70/pyRAD -n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "\r\n",
        "     ------------------------------------------------------------\r\n",
        "      pyRAD : RADseq for phylogenetics & introgression analyses\r\n",
        "     ------------------------------------------------------------\r\n",
        "\r\n",
        "\tnew params.txt file created\r\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Let's take a look at the default settings."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! cat params.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "@@&&###########     pyRAD input file, version 1.70    ##############&&@@\r\n",
        "./                          ## 1. Working directory\r\n",
        "./*.fastq.gz                ## 2. Loc. of non-demultiplexed files (if not line 18)\r\n",
        "./*.barcodes                ## 3. Loc. of barcode file (if not line 18)\r\n",
        "usearch7.0.1090_i86linux32  ## 4. command (or path) to call usearch v.7 \r\n",
        "muscle                      ## 5. command (or path) to call muscle\r\n",
        "TGCAG                       ## 6. recognition site/s (e.g., C|TGCAG -> TGCAG)\r\n",
        "2                           ## 7. N processors to use in parallel\r\n",
        "6                           ## 8. Mindepth: minimum depth of coverage for a cluster\r\n",
        "4                           ## 9. NQual: max # lowqual sites in read (minQ on line 20)\r\n",
        ".90                         ## 10. Wclust: clustering threshold as a decimal\r\n",
        "rad                         ## 11. Datatype: rad,gbs,ddrad,pairgbs,pairddrad,nextrad \r\n",
        "4                           ## 12. MinCov: min samples in a final locus \r\n",
        "3                           ## 13. MaxSharedH: exclude loci w/ H shared in >N samples\r\n",
        "c90d6m4p3                   ## 14. prefix name for final output (no spaces)\r\n",
        "==========================================================================================\r\n",
        "                       ## 15.optional: only execute on subset (prefix name) of samples\r\n",
        "                       ## 16.optional: add-on (outgroup) taxa, ( ',' separated -no spaces)\r\n",
        "                       ## 17.optional: exclude taxa (',' separated -no spaces), only step 7\r\n",
        "                       ## 18.optional: Loc. of de-multiplexed data (for step 2)\r\n",
        "                       ## 19.optional: maxM: mismatches in barcode during sorting (def. 1)\r\n",
        "                       ## 20.optional: MinQ: Phred Quality score after offset (def. 20)\r\n",
        "                       ## 21.optional: Filter: def=0=NQual. 1=NQual+adapters. 2=1+strict\r\n",
        "                       ## 22.optional: a priori E,H (def. 0.001,0.01, if not estimated)\r\n",
        "                       ## 23.optional: maxN: Ns in a consensus seq (def. 4)\r\n",
        "                       ## 24.optional: maxH: heterozygous sites in consensus seq (def. 4)\r\n",
        "                       ## 25.optional: maxHaplos: max alleles in a consens seqs (def.=2)\r\n",
        "                       ## 26.optional: maxSNPs: step 7. (def=100). Paired (def=100,100)\r\n",
        "                       ## 27.optional: maxIndels: in within-sample clusters (def. 3)\r\n",
        "                       ## 28.optional: random number seed (default 112233)\r\n",
        "                       ## 29.optional: overhang left or right of final loc (1,1) def=0,0\r\n",
        "                       ## 30.optional: add output formats: a,n,s,u (see documentation)\r\n",
        "==========================================================================================\r\n",
        "                       ## 31.optional: clustprefix for hierarchical clustering (ex: a,b,c)\r\n",
        "                       ## 32.optional: min hits for each clustprefix (ex: 4,4,4)\r\n",
        "==========================================================================================\r\n",
        "                       ## 33.optional: call maj. consens if depth < stat. limit (def. 0)\r\n",
        "                       ## 34.optional: merge/remove pair overlap (def 0) enter min overlap\r\n",
        "                       ## 35.optional: keep short fragment reads (def=0). Enter min length.\r\n",
        "                       ## 36.optional: max stack size (int), def= max(500,mean+2*SD)\r\n",
        "                       ## 37.optional: minDerep: exclude dereps with <= N copies, def=0\r\n",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### We want to change a few of these. You should do this by editing params.txt with any text editor. I use the script below to make the changes here. The most important changes below are the following effects:  \n",
      "\n",
      "+ line 11 sets the datatype to 'gbs', meaning we will test for reverse-complement clusters in step 3\n",
      "+ line 14 sets 1 difference between barcodes, b/c I did not simulate a minimum of 2. Used in step 1\n",
      "+ line 21 sets filter to 1, meaning we will trim reads with an Illumina adapter detected in step 2.\n",
      "+ line 37 sets the minimum length of kept trimmed reads from the filter in step 2."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "sed -i '/## 10. /c\\.85                 ## 10. lowered clust thresh... ' params.txt\n",
      "sed -i '/## 11. /c\\gbs                 ## 11. changed datatype to gbs ' params.txt\n",
      "sed -i '/## 14. /c\\c85m4p3             ## 14. outprefix... ' params.txt\n",
      "sed -i '/## 19./c\\0                    ## 19. no bar mismatch... ' params.txt\n",
      "sed -i '/## 21./c\\1                    ## 21. set filter to 1 ' params.txt\n",
      "sed -i '/## 30./c\\a,s,n,u              ## 30. more output formats... ' params.txt\n",
      "sed -i '/## 35./c\\50                   ## 35. keep fragments longer than 50 ' params.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! cat params.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "@@&&###########     pyRAD input file, version 1.70    ##############&&@@\r\n",
        "./                          ## 1. Working directory\r\n",
        "./*.fastq.gz                ## 2. Loc. of non-demultiplexed files (if not line 18)\r\n",
        "./*.barcodes                ## 3. Loc. of barcode file (if not line 18)\r\n",
        "usearch7.0.1090_i86linux32  ## 4. command (or path) to call usearch v.7 \r\n",
        "muscle                      ## 5. command (or path) to call muscle\r\n",
        "TGCAG                       ## 6. recognition site/s (e.g., C|TGCAG -> TGCAG)\r\n",
        "2                           ## 7. N processors to use in parallel\r\n",
        "6                           ## 8. Mindepth: minimum depth of coverage for a cluster\r\n",
        "4                           ## 9. NQual: max # lowqual sites in read (minQ on line 20)\r\n",
        ".85                 ## 10. lowered clust thresh... \r\n",
        "gbs                 ## 11. changed datatype to gbs \r\n",
        "4                           ## 12. MinCov: min samples in a final locus \r\n",
        "3                           ## 13. MaxSharedH: exclude loci w/ H shared in >N samples\r\n",
        "c85m4p3             ## 14. outprefix... \r\n",
        "==========================================================================================\r\n",
        "                       ## 15.optional: only execute on subset (prefix name) of samples\r\n",
        "                       ## 16.optional: add-on (outgroup) taxa, ( ',' separated -no spaces)\r\n",
        "                       ## 17.optional: exclude taxa (',' separated -no spaces), only step 7\r\n",
        "                       ## 18.optional: Loc. of de-multiplexed data (for step 2)\r\n",
        "0                    ## 19. no bar mismatch... \r\n",
        "                       ## 20.optional: MinQ: Phred Quality score after offset (def. 20)\r\n",
        "1                    ## 21. set filter to 1 \r\n",
        "                       ## 22.optional: a priori E,H (def. 0.001,0.01, if not estimated)\r\n",
        "                       ## 23.optional: maxN: Ns in a consensus seq (def. 4)\r\n",
        "                       ## 24.optional: maxH: heterozygous sites in consensus seq (def. 4)\r\n",
        "                       ## 25.optional: maxHaplos: max alleles in a consens seqs (def.=2)\r\n",
        "                       ## 26.optional: maxSNPs: step 7. (def=100). Paired (def=100,100)\r\n",
        "                       ## 27.optional: maxIndels: in within-sample clusters (def. 3)\r\n",
        "                       ## 28.optional: random number seed (default 112233)\r\n",
        "                       ## 29.optional: overhang left or right of final loc (1,1) def=0,0\r\n",
        "a,s,n,u              ## 30. more output formats... \r\n",
        "==========================================================================================\r\n",
        "                       ## 31.optional: clustprefix for hierarchical clustering (ex: a,b,c)\r\n",
        "                       ## 32.optional: min hits for each clustprefix (ex: 4,4,4)\r\n",
        "==========================================================================================\r\n",
        "                       ## 33.optional: call maj. consens if depth < stat. limit (def. 0)\r\n",
        "                       ## 34.optional: merge/remove pair overlap (def 0) enter min overlap\r\n",
        "50                   ## 35. keep fragments longer than 50 \r\n",
        "                       ## 36.optional: max stack size (int), def= max(500,mean+2*SD)\r\n",
        "                       ## 37.optional: minDerep: exclude dereps with <= N copies, def=0\r\n",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Let's take a look at what the raw data look like."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Your input data will be in fastQ format, usually ending in .fq or .fastq. Your data could be split among multiple files, or all within a single file. The file/s may be compressed with gzip so that they have a .gz, but do not need to be compressed. The location of these files should be entered on line 2 of the params file unless your data are already demultiplexed in which case you can skip this step and instead list the location of your demultiplexed files on line 18. Below are the first three reads in the example data set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash \n",
      "less simGBS_R1_001.fastq.gz | head -n 12"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "@lane1_fakedata0_R1_0 1:N:0:\n",
        "TTAAGATGCAGAAGTGGAGACAGAGATCATACACGATTGCTGCCGCCTCTACCCGACATTTGCCACATATATGCTTGGCTTGCAATACGAATAACAATAG\n",
        "+\n",
        "BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB\n",
        "@lane1_fakedata0_R1_0 1:N:0:\n",
        "TTAAGATGCAGTAGTCGCCATGCCGCCACGGCGTGTGGGACCGCACACCCTATTGTTATTCGTATTGCAAGCCAAGCATATATGTGGCAAATGTCGGGTA\n",
        "+\n",
        "BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB\n",
        "@lane1_fakedata0_R1_1 1:N:0:\n",
        "TTAAGATGCAGAAGTGGAGACAGAGATCATACACGATTGCTGCCGCCTCTACCCGATATTTGCCACATATATGCTTGGCTTGCAATACGAATAACAATAG\n",
        "+\n",
        "BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Each read takes four lines. The first is the name of the read (its location on the plate). The second line contains the sequence data. The third line is a spacer. And the fourth line the quality scores for the base calls. In this case arbitrarily high since the data were simulated. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These are 100 bp single-end reads prepared as GBS. The first six bases form the barcode and the next five bases (TGCAG) the restriction site overhang. All following bases make up the sequence data. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Step 1: de-multiplexing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This step uses information in the barcodes file to sort data into a separate file for each sample, which is then saved in a new directory called fastq/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! ~/pyrad_v.1.70/pyRAD -p params.txt -s 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "\r\n",
        "     ------------------------------------------------------------\r\n",
        "      pyRAD : RADseq for phylogenetics & introgression analyses\r\n",
        "     ------------------------------------------------------------\r\n",
        "\r\n",
        "\r\n",
        "\tstep 1: sorting reads by barcode\r\n",
        " "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "./home/deren/Dropbox/Public/PYRAD_TUTORIALS/tutorial_GBS/fastq/.simGBS_001.fastq.gz.pickle\r\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! ls fastq/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1A0_R1.fq.gz  1C0_R1.fq.gz  2E0_R1.fq.gz  2G0_R1.fq.gz\t3I0_R1.fq.gz  3K0_R1.fq.gz\r\n",
        "1B0_R1.fq.gz  1D0_R1.fq.gz  2F0_R1.fq.gz  2H0_R1.fq.gz\t3J0_R1.fq.gz  3L0_R1.fq.gz\r\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### The statistics for step 1  \n",
      "For each raw data file the number of reads is shown, the number for which the cut site was detected, and the number for which the detected barcode matched in the barcodes file.  Then for each true barcode it lists the observed barcodes that matched within the allowed number of mismatches, and their number of occurrences. Finally at the bottom the non-matching barcodes are shown, and their occurrences as well."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! cat stats/s1.sorting.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "file    \tNreads\tcut_found\tbar_matched\r\n",
        "simGBS_001.fastq.gz\t480000\t480000\t480000\r\n",
        "\r\n",
        "total_kept_reads = 480000\r\n",
        "\r\n",
        "\r\n",
        "sample\ttrue_bar\tobs_bars\tN_obs\r\n",
        "2E0    \tAGAGAA    \tAGAGAA\t40000   \r\n",
        "3J0    \tAGGGAA    \tAGGGAA\t40000   \r\n",
        "2F0    \tATAAAT    \tATAAAT\t40000   \r\n",
        "1D0    \tATATTT    \tATATTT\t40000   \r\n",
        "3L0    \tGGGGGA    \tGGGGGA\t40000   \r\n",
        "3I0    \tGGTAGA    \tGGTAGA\t40000   \r\n",
        "2G0    \tGTAGTT    \tGTAGTT\t40000   \r\n",
        "1C0    \tTATGGA    \tTATGGA\t40000   \r\n",
        "1B0    \tTTAAGA    \tTTAAGA\t40000   \r\n",
        "2H0    \tTTAAGG    \tTTAAGG\t40000   \r\n",
        "1A0    \tTTGAAT    \tTTGAAT\t40000   \r\n",
        "3K0    \tTTGGGG    \tTTGGGG\t40000   \r\n",
        "\r\n",
        "nomatch  \t_       \t0\r\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Step 2: quality filtering"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Step 2 filters reads based on quality scores, and can be used to detect and trim off Illumina adapters if present, which we expect to have in these simulated data. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! ~/pyrad_v.1.70/pyRAD -p params.txt -s 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "\r\n",
        "     ------------------------------------------------------------\r\n",
        "      pyRAD : RADseq for phylogenetics & introgression analyses\r\n",
        "     ------------------------------------------------------------\r\n",
        "\r\n",
        "\tstep 2: editing raw reads \r\n",
        "\t"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! ls edits/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1A0.edit  1B0.edit  1C0.edit  1D0.edit\t2E0.edit  2F0.edit  2G0.edit  2H0.edit\t3I0.edit  3J0.edit  3K0.edit  3L0.edit\r\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The filtered data are written in fasta format (quality scores removed) into a new directory called edits/ "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! head -n 10 edits/1A0.edit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">1A0_0_r1\r\n",
        "TGCAGAAGTGGAGACAGAGATCATACACGATTGCTGCCGCCTCTACCCGATATTTGCCACATATATGCTTGGCTTGCAATACGAATAACAATAG\r\n",
        ">1A0_1_r1\r\n",
        "TGCAGTAGTCGCCATGCCGCCACGGCGTGTGGGACCGCACACCCTATTGTTATTCGTATTGCAAGCCAAGCATATATGTGGCAAATATCGGGTA\r\n",
        ">1A0_2_r1\r\n",
        "TGCAGAAGTGGAGACAGAGATCATACACGATTGCTGCCGCCTCTACCCGATATTTGCCACATATATGCTTGGCTTGCAATACGAATAACAATAG\r\n",
        ">1A0_3_r1\r\n",
        "TGCAGTAGTCGCCATGCCGCCACGGCGTGTGGGACCGCACACCCTATTGTTATTCGTATTGCAAGCCAAGCATATATGTGGCAAATATCGGGTA\r\n",
        ">1A0_4_r1\r\n",
        "TGCAGAAGTGGAGACAGAGATCATACACGATTGCTGCCGCCTCTACCCGATATTTGCCACATATATGCTTGGCTTGCAATACGAATAACAATAG\r\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can see here that of the 40K reads for each sample a little less than 10% were filtered out. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! cat stats/s2.rawedit.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sample\tNreads\tpassed\tadapter\tpassed.w.trim\r\n",
        "1A0\t40000\t36780\t3220\t40000\r\n",
        "1B0\t40000\t36780\t3220\t40000\r\n",
        "1C0\t40000\t36778\t3220\t39998\r\n",
        "1D0\t40000\t36777\t3221\t39998\r\n",
        "2E0\t40000\t36779\t3220\t39999\r\n",
        "2F0\t40000\t36780\t3220\t40000\r\n",
        "2G0\t40000\t36780\t3220\t40000\r\n",
        "2H0\t40000\t36779\t3220\t39999\r\n",
        "3I0\t40000\t36780\t3220\t40000\r\n",
        "3J0\t40000\t36780\t3220\t40000\r\n",
        "3K0\t40000\t36779\t3220\t39999\r\n",
        "3L0\t40000\t36780\t3220\t40000\r\n",
        "\r\n",
        "    Nreads = total number of reads for a sample\r\n",
        "    passed = reads that passed quality filtering at full length\r\n",
        "    adapter= reads that were trimmed due to detection of adapters\r\n",
        "    total  = passed + trimmed seqs of sufficient length\r\n",
        "    note: you can set the option in params file to include trimmed reads of xx length. \r\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Step 3: clustering within-samples"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Step 3 de-replicates and then clusters reads within samples by the set clustering threshold and writes the clusters to new files in a directory called clust.xx.  \n",
      "\n",
      "Below I show the results of this analysis which uses reverse complement clustering to detect overlap among sequences originating from either end of short GBS fragments. I then show how to check for overlap in your data, and how to turn off reverse complement clustering if overlap is not detected, because it will allow your analysis to run much faster.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! ~/pyrad_v.1.70/pyRAD -p params.txt -s 3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "\r\n",
        "     ------------------------------------------------------------\r\n",
        "      pyRAD : RADseq for phylogenetics & introgression analyses\r\n",
        "     ------------------------------------------------------------\r\n",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "\tde-replicating files for clustering...\r\n",
        "\r\n",
        "\tstep 3: within-sample clustering of 12 samples at '.85' similarity using up to 2 processors\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/deren/Dropbox/Public/PYRAD_TUTORIALS/tutorial_GBS/edits/1A0.edit clustering\r\n",
        "usearch7.0.1090_i86linux32 -cluster_smallmem /home/deren/Dropbox/Public/PYRAD_TUTORIALS/tutorial_GBS/edits/1A0.derep -strand both  -query_cov .40  -id .85 -userout /home/deren/Dropbox/Public/PYRAD_TUTORIALS/tutorial_GBS/clust.85/1A0.u -userfields query+target+id+gaps+qstrand+qcov -maxaccepts 1 -maxrejects 0 -minsl 0.5 -fulldp -usersort  -notmatched /home/deren/Dropbox/Public/PYRAD_TUTORIALS/tutorial_GBS/clust.85/1A0._temp -quiet\r\n",
        "/home/deren/Dropbox/Public/PYRAD_TUTORIALS/tutorial_GBS/edits/2G0.edit clustering\r\n",
        "usearch7.0.1090_i86linux32 -cluster_smallmem /home/deren/Dropbox/Public/PYRAD_TUTORIALS/tutorial_GBS/edits/2G0.derep -strand both  -query_cov .40  -id .85 -userout /home/deren/Dropbox/Public/PYRAD_TUTORIALS/tutorial_GBS/clust.85/2G0.u -userfields query+target+id+gaps+qstrand+qcov -maxaccepts 1 -maxrejects 0 -minsl 0.5 -fulldp -usersort  -notmatched /home/deren/Dropbox/Public/PYRAD_TUTORIALS/tutorial_GBS/clust.85/2G0._temp -quiet\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "^CProcess Worker-2:\r\n",
        "Process Worker-1:\r\n",
        "Traceback (most recent call last):\r\n",
        "Traceback (most recent call last):\r\n",
        "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\n",
        "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\r\n",
        "    self.run()\r\n",
        "  File \"/home/deren/pyrad_v.1.70/potpour.py\", line 30, in run\r\n",
        "    res = self.func(*job)\r\n",
        "  File \"/home/deren/pyrad_v.1.70/cluster7dp.py\", line 442, in final\r\n",
        "Traceback (most recent call last):\r\n",
        "  File \"/home/deren/pyrad_v.1.70/pyRAD\", line 383, in <module>\r\n",
        "    main()\r\n",
        "  File \"/home/deren/pyrad_v.1.70/pyRAD\", line 249, in main\r\n",
        "    complementmatch, minuniq)\r\n",
        "    fullcluster(UCLUST, outfolder, handle, wclust, Parallel, datatype, fileno, complementmatch)\r\n",
        "  File \"/home/deren/pyrad_v.1.70/cluster7dp.py\", line 540, in main\r\n",
        "  File \"/home/deren/pyrad_v.1.70/cluster7dp.py\", line 188, in fullcluster\r\n",
        "    subprocess.call(cmd, shell=True)\r\n",
        "  File \"/usr/lib/python2.7/subprocess.py\", line 524, in call\r\n",
        "    j.join()\r\n",
        "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 145, in join\r\n",
        "    res = self._popen.wait(timeout)\r\n",
        "  File \"/usr/lib/python2.7/multiprocessing/forking.py\", line 154, in wait\r\n",
        "    self.run()\r\n",
        "  File \"/home/deren/pyrad_v.1.70/potpour.py\", line 30, in run\r\n",
        "    res = self.func(*job)\r\n",
        "  File \"/home/deren/pyrad_v.1.70/cluster7dp.py\", line 442, in final\r\n",
        "    return self.poll(0)\r\n",
        "  File \"/usr/lib/python2.7/multiprocessing/forking.py\", line 135, in poll\r\n",
        "    pid, sts = os.waitpid(self.pid, flag)\r\n",
        "    fullcluster(UCLUST, outfolder, handle, wclust, Parallel, datatype, fileno, complementmatch)\r\n",
        "KeyboardInterrupt  File \"/home/deren/pyrad_v.1.70/cluster7dp.py\", line 188, in fullcluster\r\n",
        "\r\n",
        "    subprocess.call(cmd, shell=True)\r\n",
        "  File \"/usr/lib/python2.7/subprocess.py\", line 524, in call\r\n",
        "    return Popen(*popenargs, **kwargs).wait()\r\n",
        "  File \"/usr/lib/python2.7/subprocess.py\", line 1357, in wait\r\n",
        "    pid, sts = _eintr_retry_call(os.waitpid, self.pid, 0)\r\n",
        "  File \"/usr/lib/python2.7/subprocess.py\", line 478, in _eintr_retry_call\r\n",
        "    return func(*args)\r\n",
        "KeyboardInterrupt\r\n",
        "    return Popen(*popenargs, **kwargs).wait()\r\n",
        "  File \"/usr/lib/python2.7/subprocess.py\", line 1357, in wait\r\n",
        "    pid, sts = _eintr_retry_call(os.waitpid, self.pid, 0)\r\n",
        "  File \"/usr/lib/python2.7/subprocess.py\", line 478, in _eintr_retry_call\r\n",
        "    return func(*args)\r\n",
        "KeyboardInterrupt\r\n",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! ls clust.85/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1A0.clustS.gz  1B0.u\t      1D0._temp      2F0.clustS.gz  2G0.u\t   3I0._temp\t  3K0.clustS.gz  3L0.u\r\n",
        "1A0._temp      1C0.clustS.gz  1D0.u\t     2F0._temp\t    2H0.clustS.gz  3I0.u\t  3K0._temp\r\n",
        "1A0.u\t       1C0._temp      2E0.clustS.gz  2F0.u\t    2H0._temp\t   3J0.clustS.gz  3K0.u\r\n",
        "1B0.clustS.gz  1C0.u\t      2E0._temp      2G0.clustS.gz  2H0.u\t   3J0._temp\t  3L0.clustS.gz\r\n",
        "1B0._temp      1D0.clustS.gz  2E0.u\t     2G0._temp\t    3I0.clustS.gz  3J0.u\t  3L0._temp\r\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### As you can see, we recovered overlapping reads using reverse complement clustering.   "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! less clust.85/1A0.clustS.gz | head -n 26"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">1A0_18220_r1;size=19;\r\n",
        "TGCAGACGGGCCGTGCACGTGGGGTGCTCTCCGCCCTTCACACGAAGTCCGAGATAAAGTACGTCGTAACAGAAAGCGGGACTGACCCTTTGAC\r\n",
        ">1A0_18221_r1;size=1;+\r\n",
        "TGCAGACGGGCCGTGCACGTGGGGTGCTCTCCGCCCTTCACACGAAGTCCGAGATAAAGAACGTCGTAACAGAAAGCGGGACTGACCCTTTGAC\r\n",
        "//\r\n",
        "//\r\n",
        ">1A0_7820_r1;size=19;\r\n",
        "TGCAGACCGTCAATGGGCATCTCTGTGTTTACGCGGCAAGGGAGAAGTCTTCACTAGGTTTTGGATGGACCAAGTCGGGACGAGTTGCTCATTG\r\n",
        ">1A0_7824_r1;size=1;+\r\n",
        "TGCAGACCGTCAATGGGCATCTCTGTGTTTACGCGGCAAGGGAGAAGTCTTCACTAGGTTTTGGATGGACCAAGTCGGGACGAGTTGCTCGTTG\r\n",
        "//\r\n",
        "//\r\n",
        ">1A0_17300_r1;size=18;\r\n",
        "TGCAGCCATACCTTGCGGGGGTAATCTGTAGTACAGCAGGTGTATTGAGTACAACTGAACTTTTAAGGTATTTAGCCCGCCGCATTATGCCTCC\r\n",
        ">1A0_17307_r1;size=1;+\r\n",
        "TGCAGCCACACCTTGCGGGGGTAATCTGTAGTACAGCAGGTGTATTGAGTACAACTGAACTTTTAAGGTATTTAGCCCGCCGCATTATGCCTCC\r\n",
        ">1A0_17308_r1;size=1;+\r\n",
        "TGCAGCCATACCTTGCGGGGGTAATCTGTAGTACAGCAGGTGTATTGAGTACAACTGATCTTTTAAGGTATTTAGCCCGCCGCATTATGCCTCC\r\n",
        "//\r\n",
        "//\r\n",
        ">1A0_2880_r1;size=19;\r\n",
        "TGCAGTAAAAAGCAGTACTTCATTTGATATTAAAATGAGTATGTGATCCGCCGGAGGCCAGACGTTCAACCACCAGCAATAGGGACTATAGTCG\r\n",
        ">1A0_2882_r1;size=1;+\r\n",
        "TGCAGTAAAAAGCAGTACTTCATTTGATATTAAAATGAGTATGTGATCCGCCGGAGGCCAGTCGTTCAACCACCAGCAATAGGGACTATAGTCG\r\n",
        "//\r\n",
        "//\r\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The stats output tells you how many clusters were found, and their mean depth of coverage. It also tells you how many pass  your minimum depth setting. You can use this information to decide if you wish to increase or decrease the mindepth."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! cat stats/s3.clusters.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "taxa\ttotal\tdpt.me\tdpt.sd\td>5.tot\td>5.me\td>5.sd\tbadpairs\r\n",
        "1A0\t1000\t20.0\t0.0\t1000\t20.0\t0.0\t0\r\n",
        "1D0\t1000\t20.0\t0.0\t1000\t20.0\t0.0\t0\r\n",
        "2G0\t1000\t20.0\t0.0\t1000\t20.0\t0.0\t0\r\n",
        "2E0\t1000\t20.0\t0.0\t1000\t20.0\t0.0\t0\r\n",
        "2H0\t1000\t20.0\t0.0\t1000\t20.0\t0.0\t0\r\n",
        "3I0\t1000\t20.0\t0.0\t1000\t20.0\t0.0\t0\r\n",
        "2F0\t1000\t20.0\t0.0\t1000\t20.0\t0.0\t0\r\n",
        "3L0\t1000\t20.0\t0.0\t1000\t20.0\t0.0\t0\r\n",
        "1B0\t1000\t20.0\t0.0\t1000\t20.0\t0.0\t0\r\n",
        "3K0\t1000\t20.0\t0.0\t1000\t20.0\t0.0\t0\r\n",
        "3J0\t1000\t20.0\t0.0\t1000\t20.0\t0.0\t0\r\n",
        "1C0\t1000\t20.0\t0.0\t1000\t20.0\t0.0\t0\r\n",
        "\r\n",
        "    ## total = total number of clusters, including singletons\r\n",
        "    ## dpt.me = mean depth of clusters\r\n",
        "    ## dpt.sd = standard deviation of cluster depth\r\n",
        "    ## >N.tot = number of clusters with depth greater than N\r\n",
        "    ## >N.me = mean depth of clusters with depth greater than N\r\n",
        "    ## >N.sd = standard deviation of cluster depth for clusters with depth greater than N\r\n",
        "    ## badpairs = mismatched 1st & 2nd reads (only for paired ddRAD data)\r\n",
        "    \r\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Toggling reverse-complement clustering   \n",
      "\n",
      "For any single end GBS analysis I suggest that you first begin step 3 with the datatype (line 11) set to gbs, which tells _pyRAD_ to perform reverse complement clustering. Let this run for about 15 minutes, and then look at the resulting data file in the clust directory that has a \".u\" ending, using the unix command \"less\". I use the command \"head\" below to print only the first 20 lines. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! head -n 20 clust.85/1A0.u"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The \".u\" file records the clustering process, showing which hits match to seeds, their measured similarity, the direction in which they match, and the number of indels. If your data do not contain any reverse complement clusters, meaning you see only \"+\" in column x, and no \"-\", then you do not need to use reverse complement clustering. In that case you should change the datatype option on line 11 from 'gbs' to 'rad'. If you do see frequent \"-\" in column x then you should perform the rest of your analysis using the 'gbs' option.  "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Steps 4 & 5: Call consensus sequences"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Step 4 jointly infers the error-rate and heterozygosity across samples."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! ~/pyrad_v.1.70/pyRAD -p params.txt -s 4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "\r\n",
        "      ------------------------------------------------------------------\r\n",
        "          pyRAD : RAD/GBS for phylogenetics & introgression analyses\r\n",
        "      ------------------------------------------------------------------\r\n",
        "\r\n",
        "\r\n",
        "\tstep 4: estimating error rate and heterozygosity\r\n",
        "\t"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! cat stats/Pi_E_estimate.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "taxa\tH\tE\r\n",
        "2E0.clustS.gz\t0.00142634\t0.00052107\r\n",
        "2G0.clustS.gz\t0.00157261\t0.00051814\r\n",
        "1C0.clustS.gz\t0.00143890\t0.00051081\r\n",
        "2F0.clustS.gz\t0.00154940\t0.00050525\r\n",
        "3K0.clustS.gz\t0.00137238\t0.00049931\r\n",
        "1B0.clustS.gz\t0.00146097\t0.00050141\r\n",
        "1A0.clustS.gz\t0.00111275\t0.00051815\r\n",
        "1D0.clustS.gz\t0.00123800\t0.00050134\r\n",
        "3L0.clustS.gz\t0.00152736\t0.00049178\r\n",
        "3I0.clustS.gz\t0.00153822\t0.00048300\r\n",
        "3J0.clustS.gz\t0.00142652\t0.00048742\r\n",
        "2H0.clustS.gz\t0.00116838\t0.00049057\r\n",
        "mean E = 0.000502353448579\r\n",
        "mean H = 0.00140265188764"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Step 5 calls consensus sequences using the parameters inferred above, and filters for paralogs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! ~/pyrad_v.1.70/pyRAD -p params.txt -s 5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "\r\n",
        "      ------------------------------------------------------------------\r\n",
        "          pyRAD : RAD/GBS for phylogenetics & introgression analyses\r\n",
        "      ------------------------------------------------------------------\r\n",
        "\r\n",
        "\r\n",
        "\tstep 5: created consensus seqs for 12 samples, using E=0.00050 H=0.00140\r\n",
        "\t"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! cat stats/s5.consens.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "taxon               \tnloci\tf1loci\tf2loci\tnsites\tnpoly\tpoly\r\n",
        "2E0.clustS.gz       \t1000\t1000\t1000\t94002\t127\t0.001351\r\n",
        "2G0.clustS.gz       \t1000\t1000\t1000\t94000\t140\t0.0014894\r\n",
        "1C0.clustS.gz       \t1000\t1000\t1000\t94000\t128\t0.0013617\r\n",
        "2F0.clustS.gz       \t1000\t1000\t1000\t94002\t138\t0.0014681\r\n",
        "3K0.clustS.gz       \t1000\t1000\t1000\t94004\t122\t0.0012978\r\n",
        "1B0.clustS.gz       \t1000\t1000\t1000\t94001\t130\t0.001383\r\n",
        "1A0.clustS.gz       \t1000\t1000\t1000\t94001\t99\t0.0010532\r\n",
        "1D0.clustS.gz       \t1000\t1000\t1000\t94001\t110\t0.0011702\r\n",
        "3L0.clustS.gz       \t1000\t1000\t1000\t94001\t136\t0.0014468\r\n",
        "3I0.clustS.gz       \t1000\t1000\t1000\t94004\t137\t0.0014574\r\n",
        "3J0.clustS.gz       \t1000\t1000\t1000\t94000\t127\t0.0013511\r\n",
        "2H0.clustS.gz       \t1000\t1000\t1000\t94003\t104\t0.0011063\r\n",
        "\r\n",
        "    ## nloci = number of loci\r\n",
        "    ## f1loci = number of loci with >N depth coverage\r\n",
        "    ## f2loci = number of loci with >N depth and passed paralog filter\r\n",
        "    ## nsites = number of sites across f loci\r\n",
        "    ## npoly = number of polymorphic sites in nsites\r\n",
        "    ## poly = frequency of polymorphic sites\r\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Step 6: Cluster across samples"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Step 6 clusters consensus sequences across samples. Again this uses reverse complement clustering if the datatype is set to 'gbs'. This step can take a long time for very large data sets (>100 individuals). I suggest trying it first. If it takes too long you can implement the two-step clustering method (lines 31 & 32 of the params file, described in detail in a separate tutorial)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! ~/pyrad_v.1.70/pyRAD -p params.txt -s 6 "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "\r\n",
        "      ------------------------------------------------------------------\r\n",
        "          pyRAD : RAD/GBS for phylogenetics & introgression analyses\r\n",
        "      ------------------------------------------------------------------\r\n",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "\tstep 6: clustering across 12 samples at '.85' similarity \r\n",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "usearch v7.0.1090_i86linux32, 4.0Gb RAM (7.9Gb total), 4 cores\r\n",
        "(C) Copyright 2013 Robert C. Edgar, all rights reserved.\r\n",
        "http://drive5.com/usearch\r\n",
        "\r\n",
        "Licensed to: daeaton.chicago@gmail.com\r\n",
        "\r\n",
        "00:00  21Mb    0.1% 0 clusters, max size 0, avg 0.0\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "00:01  28Mb    6.8% 568 clusters, max size 5, avg 1.4\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "00:02  28Mb   15.5% 851 clusters, max size 6, avg 2.2\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "00:03  28Mb   63.6% 1000 clusters, max size 12, avg 7.6\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "00:03  28Mb  100.0% 1000 clusters, max size 12, avg 12.0\r",
        "\r\n",
        "                                                        \r\n",
        "      Seqs  12000 (12.0k)\r\n",
        "  Clusters  1000\r\n",
        "  Max size  12\r\n",
        "  Avg size  12.0\r\n",
        "  Min size  12\r\n",
        "Singletons  0, 0.0% of seqs, 0.0% of clusters\r\n",
        "   Max mem  28Mb\r\n",
        "      Time  3.00s\r\n",
        "Throughput  4000.0 seqs/sec.\r\n",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! ~/pyrad_v.1.70/pyRAD -p params.txt -s 7"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "\r\n",
        "      ------------------------------------------------------------------\r\n",
        "          pyRAD : RAD/GBS for phylogenetics & introgression analyses\r\n",
        "      ------------------------------------------------------------------\r\n",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tingroup 1A0,1B0,1C0,1D0,2E0,2F0,2G0,2H0,3I0,3J0,3K0,3L0\r\n",
        "\taddon \r\n",
        "\texclude \r\n",
        "\t"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".\r\n",
        "\tfinal stats written to:\r\n",
        "\t /home/deren/Dropbox/Public/PYRAD_TUTORIALS/tutorial_RAD/stats/c85m4p3.stats\r\n",
        "\toutput files written to:\r\n",
        "\t /home/deren/Dropbox/Public/PYRAD_TUTORIALS/tutorial_RAD/outfiles/ directory\r\n",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Final stats output"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can see we did not recover all 1000 loci in the data set. This is because some reads were filtered for containing Illumina adapters, and others were merged when they overlapped.  Below I print the first several loci in the \".loci\" output to show the variable length loci that are recovered from this GBS analysis that included fragmented and overlapping reads.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! cat stats/c85m4p3.stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "\r\n",
        "1000        ## total loci across all samples\r\n",
        "1000        ## loci with > minsp containing data\r\n",
        "1000        ## loci with > minsp containing data & paralogs removed\r\n",
        "1000        ## loci with > minsp containing data & paralogs removed & final filtering\r\n",
        "\r\n",
        "## number of loci recovered in final data set for each taxon.\r\n",
        "taxon\tnloci\r\n",
        "1A0\t1000\r\n",
        "1B0\t1000\r\n",
        "1C0\t1000\r\n",
        "1D0\t1000\r\n",
        "2E0\t1000\r\n",
        "2F0\t1000\r\n",
        "2G0\t1000\r\n",
        "2H0\t1000\r\n",
        "3I0\t1000\r\n",
        "3J0\t1000\r\n",
        "3K0\t1000\r\n",
        "3L0\t1000\r\n",
        "\r\n",
        "\r\n",
        "## nloci = number of loci with data for exactly ntaxa\r\n",
        "## ntotal = number of loci for which at least ntaxa have data\r\n",
        "ntaxa\tnloci\tsaved\tntotal\r\n",
        "1\t0\r\n",
        "2\t0\t\t-\r\n",
        "3\t0\t\t-\r\n",
        "4\t0\t*\t1000\r\n",
        "5\t0\t*\t1000\r\n",
        "6\t0\t*\t1000\r\n",
        "7\t0\t*\t1000\r\n",
        "8\t0\t*\t1000\r\n",
        "9\t0\t*\t1000\r\n",
        "10\t0\t*\t1000\r\n",
        "11\t0\t*\t1000\r\n",
        "12\t1000\t*\t1000\r\n",
        "\r\n",
        "\r\n",
        "## var = number of loci containing n variable sites.\r\n",
        "## pis = number of loci containing n parsimony informative sites.\r\n",
        "n\tvar\tPIS\r\n",
        "0\t74\t289\r\n",
        "1\t539\t375\r\n",
        "2\t465\t210\r\n",
        "3\t309\t93\r\n",
        "4\t176\t23\r\n",
        "5\t83\t9\r\n",
        "6\t38\t1\r\n",
        "7\t22\t0\r\n",
        "8\t5\t0\r\n",
        "total var= 3937\r\n",
        "total pis= 1217\r\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! head -n 200 output/c85d6m4p3.loci "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}